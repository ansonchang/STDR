{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import csv\n",
    "from PIL import Image,ImageDraw,ImageFont,ImageOps\n",
    "#from imutils import perspective\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先跑 Validation\n",
    "Is_train=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先跑 Train\n",
    "Is_train=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Is_train: \n",
    "    img_path='/workspace/text_spot_rec/data/train_label.txt'\n",
    "if not Is_train:    \n",
    "    img_path='/workspace/text_spot_rec/data/test_label.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "\t# initialize a list of coordinates that will be ordered\n",
    "\t# such that the first entry in the list is the top-left,\n",
    "\t# the second entry is the top-right, the third is the\n",
    "\t# bottom-right, and the fourth is the bottom-left\n",
    "\trect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\t# the top-left point will have the smallest sum, whereas\n",
    "\t# the bottom-right point will have the largest sum\n",
    "\ts = pts.sum(axis=1)\n",
    "\trect[0] = pts[np.argmin(s)]\n",
    "\trect[2] = pts[np.argmax(s)]\n",
    "\t# now, compute the difference between the points, the\n",
    "\t# top-right point will have the smallest difference,\n",
    "\t# whereas the bottom-left will have the largest difference\n",
    "\tdiff = np.diff(pts, axis=1)\n",
    "\trect[1] = pts[np.argmin(diff)]\n",
    "\trect[3] = pts[np.argmax(diff)]\n",
    "\t# return the ordered coordinates\n",
    "\treturn rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "dic={}\n",
    "with open(os.path.join(img_path), 'r') as f:\n",
    "        for i in f:\n",
    "            img=i.split('\\t')[0].split('/')[-1]\n",
    "            tmp=i.split('\\t')[-1]\n",
    "            tmp=tmp[1:len(tmp)-1]\n",
    "            #print(tmp)\n",
    "            if tmp[-2:]=='}]':\n",
    "                 #tmp=tmp[0:len(tmp)-2] \n",
    "                tmp=tmp.replace(\"}]\",\"\")\n",
    "                #print(tmp)\n",
    "            tmp_list=tmp.split('},')\n",
    "            #print(tmp_list)\n",
    "            for j in range(len(tmp_list)):\n",
    "                tmp_str=tmp_list[j].strip().replace('\\\\\\\\\"','')\n",
    "                #print(tmp_str)\n",
    "                if tmp_str[-1]==']':\n",
    "                    tmp_str=tmp_str+'}'\n",
    "                #print(tmp_str)\n",
    "                dic=ast.literal_eval(tmp_str)\n",
    "                result.append([img,dic['points'][0][0],dic['points'][0][1],\n",
    "                               dic['points'][1][0],dic['points'][1][1],\n",
    "                               dic['points'][2][0],dic['points'][2][1],\n",
    "                               dic['points'][3][0],dic['points'][3][1],\n",
    "                               dic['transcription']])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp=pd.DataFrame(result)\n",
    "df_tmp.columns=['img','X0','Y0','X1','Y1','X2','Y2','X3','Y3','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Is_train: \n",
    "    df_tmp.to_csv('data/Task3_train_label.csv',index=False)\n",
    "if not Is_train: \n",
    "    df_tmp.to_csv('data/Task3_val_label.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImg(imgName, imgPath, points,output_img_path,newImgName):\n",
    "  #  img = cv2.imread('./test_data/public/public/img_public/img_6000.jpg')\n",
    "    img = cv2.imread(imgPath+imgName)\n",
    "\n",
    "    #cropped = perspective.four_point_transform(img, points[0])\n",
    "    cropped = four_point_transform(img, points[0]) \n",
    "    cv2.imwrite(output_img_path+newImgName, cropped)\n",
    "    \n",
    "    w=cropped.shape[1]\n",
    "    h=cropped.shape[0]\n",
    "    if w*1.4 < h:\n",
    "        #print (width,height)\n",
    "        cropped = cv2.rotate(cropped, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        cv2.imwrite(output_img_path+newImgName, cropped)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "train_data_path = '/workspace/text_spot_rec/data/'\n",
    "train_img_src_path = '/workspace/text_spot_rec/data/train/img/'\n",
    "train_img_out_path = '/workspace/text_spot_rec/data/train_crop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "val_data_path = '/workspace/text_spot_rec/data/'\n",
    "val_img_src_path = '/workspace/text_spot_rec/data/train/img/'\n",
    "val_img_out_path = '/workspace/text_spot_rec/data/val_crop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Private dataset\n",
    "private_data_path = '/workspace/text_spot_rec/data/'\n",
    "private_img_src_path = '/workspace/text_spot_rec/data/private/'\n",
    "private_img_out_path = '/workspace/text_spot_rec/data/private_crop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public dataset\n",
    "public_data_path = '/workspace/text_spot_rec/data/'\n",
    "public_img_src_path = '/workspace/text_spot_rec/data/public/'\n",
    "public_img_out_path = '/workspace/text_spot_rec/data/public_crop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Is_train: \n",
    "     df_label = pd.read_csv(train_data_path+'Task3_train_label.csv')\n",
    "if not Is_train:\n",
    "     df_label = pd.read_csv(train_data_path+'Task3_val_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.Y0=df_label.Y0.astype(np.int64)\n",
    "df_label.Y1=df_label.Y1.astype(np.int64)\n",
    "df_label.Y2=df_label.Y2.astype(np.int64)\n",
    "df_label.Y3=df_label.Y3.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.to_csv('data/Task3_train_label.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Private\n",
    "#df_label = pd.read_csv(private_data_path+'Task3_private_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Public\n",
    "#df_label = pd.read_csv(public_data_path+'Task3_public_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label['points']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list =df_label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['img_913.jpg', 610, 701, ..., 832, '日月光國際飯店', ''],\n",
       "       ['img_913.jpg', 94, 748, ..., 863, 'HOTEL', ''],\n",
       "       ['img_3295.jpg', 143, 623, ..., 696, '貓咪貓奴', ''],\n",
       "       ...,\n",
       "       ['img_10836.jpg', 377, 894, ..., 942, 'UNOCHA', ''],\n",
       "       ['img_10836.jpg', 312, 961, ..., 989, 'TAIWAN', ''],\n",
       "       ['img_10836.jpg', 624, 969, ..., 997, 'TEA', '']], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(df_list)\n",
    "for i in range(length):\n",
    "    df_list[i][10]= np.asarray([[[df_list[i][1],df_list[i][2]],\n",
    "                                [df_list[i][3],df_list[i][4]],\n",
    "                                [df_list[i][5],df_list[i][6]],\n",
    "                                [df_list[i][7],df_list[i][8]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11689"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewImgName(Strcount):\n",
    "    while len(Strcount)<5:\n",
    "        Strcount='0'+Strcount\n",
    "    return Strcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropSourceImg(img_src_path,img_out_path):\n",
    "    data_counter = 1  \n",
    "    for img in df_list:\n",
    "        tmp = img_src_path + img[0]\n",
    "        #print(tmp)\n",
    "        cropImg(img[0], img_src_path, img[10], img_out_path, getNewImgName(str(data_counter))+'_'+img[0])\n",
    "        data_counter = data_counter + 1\n",
    "    print('finished !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished !\n"
     ]
    }
   ],
   "source": [
    "if Is_train:\n",
    "    cropSourceImg(train_img_src_path,train_img_out_path)\n",
    "if not Is_train:\n",
    "    cropSourceImg(val_img_src_path,val_img_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropSourceImg(public_img_src_path,public_img_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropSourceImg(private_img_src_path,private_img_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "paddle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
